---
title: 第一阶段
date: 2021-01-27
autoGroup-1: 机器学习
tags:
  - Knowledge
# navbar: false
ppt:
    showPage: true
    listStyle:
---

::: tip
在这里记录机器学习笔记
:::

<!-- more -->


## 基本数学

:::::: tabs type: card
::: tab sigma域

概率空间由样本空间$\Omega$, 事件集合$\mathcal{F}$和概率测度$\mathcal{P}$组成

- 样本空间： 试验中所有可能结果的集合，每个结果互斥，所有可能结果必须被穷尽
- 事件集合： 由样本空间的一些子集构成的集合, 必须是$\sigma$-field, 即包含三点特性
    + 必须包含不可能事件
    + 事件的互补事件必须也被包含
    + 事件的union合集也必须被包含
- 概率测度： 描述一次随机试验中被包含在**事件集合**中的所有事件的可能性, 也对应上面的三个特性
    + 概率在 0 到 1 之间
    + 总的样本空间概率为1 (由事件集合的第1,2推出)
    + 如果事件互斥, 那么联合概率等于概率的和 (由事件集合的第3推出)

__例子__： 一辆车从$12:00$到$01:00$的任何时间都可以到达, 这时$\Omega$有无穷多个, 并且还不可数(无穷但按照某种标准如大小编号, 可以把他们数完), 那么就没有办法对任何一个结果$\omega$分配一个概率, 但是直觉会告诉你概率表达式应该是这个样子(正好符合事件集合的三个特性, $\sigma$-field)
$$P([x_1, x_2]) = x_2 - x_1, \quad \forall 0 \leq x_1 \leq x_2 \leq 1$$
:::
::::: tab 分部积分
核心公式
$$\int uv' dx = uv - \int u'v dx$$
- 求高脚本的容积? 其侧壁的曲线函数$y=\exp(x)$, 半径从$0$到$1$的圆
:::: col-wrapper
::: col-half
$$\begin{aligned}
    V &= \int_1^e \pi (\ln y) dy \\
      &= (\pi y\ln^2 y)\vert_1^e - 2\pi\int_1^e \ln y dy \\
      &= \pi(y\ln^2 y - 2y\ln y + 2y)\vert_1^e = \pi(e - 2)
\end{aligned}$$
:::
::: col-half
![](http://images2017.cnblogs.com/blog/1203675/201711/1203675-20171122141954086-6919942.png)
:::
::::
:::::
::::::



## 模型拟合与正则化

假设真实函数是$y = sin 2 x$, 现在用多项式($M = 1,3,5,9$)去拟合它, 然后加入$l_2$正则项去缓解过拟合问题
:::: tabs type: card
为了防止过拟合： 1）要么多加数据, 还不能太噪音; 2）要么加一些正则项去限制模型的表达
::: tab 一次项
![一次项拟合](~@assets/ml_01_01.png#center)
:::
::: tab 三次项
![三次项拟合](~@assets/ml_01_02.png#center)
:::
::: tab 五次项
![五次项拟合](~@assets/ml_01_03.png#center)
:::
::: tab 九次项
![九次项拟合](~@assets/ml_01_04.png#center)
:::
::::

## 感知机

::: right
如果存在一个超平面将所有实例正确的分在平面两侧，称线性可分数据集，否则线性不可分
:::

:::: tabs type: card
::: tab 策略
感知机的损失函数为 
$$L(\omega, b) = -\sum_{x_i \in M} y_i (\omega\cdot x_i + b)$$
每一个分错的点$y\hat y < 0$, 选择使损失函数最小的模型参数$\omega, b$
:::
::: tab 步骤
__目标__: 输出$\omega, b$, 感知机$f(x) = sign(\omega \cdot x + b)$

1. 选取初始$\omega_0, b_0$
2. 选择训练集数据$(x_i, y_i)$
3. 如果出现分错, 即$y_i(\omega x_i + b) \leq 0$, 
    $$\begin{aligned}
        \omega &\leftarrow \omega + \eta y_i x_i \\
        b &\leftarrow b + \eta y_i
    \end{aligned}$$ 
4. 但凡出现一个错分类, 回到2继续? 如果线性不可分呢?
:::
::: tab 收敛性
1. 有限次搜索可以找到将训练数据完全正确分开的超平面
2. 当训练数据集线性可分时，感知机学习算法原始形式迭代是收敛的
3. 感知机学习算法存在许多解，既依赖于初值，也依赖于迭代过程中误分类点的选择顺序。 为保证唯一性, 需要增加约束条件
4. 当训练集线性不可分时，感知机学习算法不收敛，迭代结果会发生震荡
:::
::: tab 结果
![感知机分类](~@assets/ml_01_05.png#center)
::::

## K近邻法

::: right
三要素：k值的选择, 距离度量, 分类决策规则, 三要素确定后, 任何实例分类都是唯一的
:::

:::: tabs type: card
::: tab 步骤
1. 根据距离度量, 在训练集中找出与$x$最邻近的$k$个点，涵盖这$k$个点的$x$的邻近区域被标记为$N_k(x)$
2. 在$N_k(x)$中根据分类决策规则(例如多数计票)来决定$x$的类别$y$

![KD近邻](~@assets/ml_01_07.png#center)
:::
::: tab 距离度量
空间中两个点的距离是两个实例**相似程度**的反映
1. 欧氏距离
    $$L_2(x_i, x_j) = \Big(\sum_{l=1}^m |x_i^{(l)}-x_j^{(l)}|^2\Big)^{\frac{1}{2}}$$
2. 曼哈顿距离
    $$L_1(x_i, x_j) = \sum_{l=1}^m |x_i^{(l)}-x_j^{(l)}|$$
3. 切比雪夫距离
    $$L_2(x_i, x_j) = \max_l |x_i^{(l)}-x_j^{(l)}|$$
:::
::: tab K值选择
k值的选择会对k近邻法的结果产生重大影响
- $k$值小, 优点是只关注与实例最相似的几个, 这样减小近似误差。 缺点就是导致预测结果对近邻的实例点非常敏感, 如果邻近的实例点恰巧是噪声，预测就会出错。 ==换句话说, k值的减小就意味着整体模型变得复杂, 容易发生过拟合==
- $k$值大, 优点是用更多的训练集来标注这个实例, 这样减小估计误差。 缺点就是与实例关系较远的也会影响分类, 导致错误分类。 ==换句话说, k值的增大就意味着整体的模型变得简单==
- 应用中, $k$值往往通过交叉验证来取值, 现在有了超参数自动化搜索, 这个就更容易了
:::
::: tab KD树
两两距离计算的复杂度是$O(N)$, KD树(二叉树的一种)可以减少计算次数
1. 输入数据`[[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]`
2. 第一次以$x_0$为依据, 排序, 找中间点, 分一半数据$x_0 < 7$, 另一半$x_0 \geq 7$
3. 然后左右子节点分别以$x_1$为依据, 排序, 找中间点. 比如左子节点, 分一半数据$x_1 < 4$, 另一半$x_1 \geq 4$
4. 这样就把这个二维平面给切割了, 如果需要找某个点的临近点, 先找到包含目标点的叶结点, 从叶节点出发, 依次退回到父节点, 不断找与目标点最近的节点
![KD树](~@assets/ml_01_06.png#center)
:::
::: tab KD找邻近
比如我们想在这颗树中找到离`[3, 4.5]`最近的节点
1. 通过二叉树先找到按维度划分的节点`[4,7]`, 计算他两的距离为$r=2.69$, 此时的超平面是$x_2 = 4$, 如果以目标点为圆心, 以$r=2.69$为半径的圆不能覆盖父节点的这个超平面, i.e., $4.5-4=0.5$, 那么就没有比较的意义了, 另一头和父节点都不用看了, 这个点绝壁全场最近
2. 接下来回到父节点`[5,4]`, 计算他两的距离为$r=2.06$, 比之前那个小, 更新最近节点
3. 然后计算父节点的另外一个子节点`[2,3]`, 计算他两距离为$r=1.80$, 比之前那个小, 更新最近节点
4. 回到`[5,4]`的父节点, 就是`[7,2]`的超平面是$x_1=7$, 那么节点离超平面的距离为$7-3=4 > 1.80$, 意味着以`[3,4.5]`为圆心, 以$r=1.80$为半径的圆到不了超平面的另外一头, 所以就没有去另外一头算距离的必要了, 所以返回这一侧的最小距离$r=1.8$就可以了
![KD树](~@assets/ml_01_06.png#center)
:::
::: tab 代码
```python
def find_nearest(tree, point):
    k = len(point)  # 数据维度

    def travel(kd_node, target, max_dist):
        if kd_node is None:
            return result([0] * k, float("inf"), 0)
        nodes_visited = 1
        s = kd_node.split  # 进行分割的维度
        pivot = kd_node.dom_elt  # 进行分割的“轴”
        if target[s] <= pivot[s]:  # 如果目标点第s维小于分割轴的对应值(目标离左子树更近)
            nearer_node = kd_node.left  # 下一个访问节点为左子树根节点
            further_node = kd_node.right  # 同时记录下右子树
        else:  # 目标离右子树更近
            nearer_node = kd_node.right  # 下一个访问节点为右子树根节点
            further_node = kd_node.left
        temp1 = travel(nearer_node, target, max_dist)  # 进行遍历找到包含目标点的区域
        nearest = temp1.nearest_point  # 以此叶结点作为“当前最近点”
        dist = temp1.nearest_dist  # 更新最近距离
        nodes_visited += temp1.nodes_visited
        if dist < max_dist:
            max_dist = dist  # 最近点将在以目标点为球心，max_dist为半径的超球体内
        temp_dist = abs(pivot[s] - target[s])  # 第s维上目标点与分割超平面的距离
        if max_dist < temp_dist:  # 判断超球体是否与超平面相交
            return result(nearest, dist, nodes_visited)  # 不相交则可以直接返回，不用继续判断
        # ----------------------------------------------------------------------
        # 计算目标点与分割点的欧氏距离
        p = np.array(pivot)
        t = np.array(target)
        temp_dist = np.linalg.norm(p-t)
        if temp_dist < dist:  # 如果“更近”
            nearest = pivot  # 更新最近点
            dist = temp_dist  # 更新最近距离
            max_dist = dist  # 更新超球体半径
        # 检查另一个子结点对应的区域是否有更近的点
        temp2 = travel(further_node, target, max_dist)
        nodes_visited += temp2.nodes_visited
        if temp2.nearest_dist < dist:  # 如果另一个子结点内存在更近距离
            nearest = temp2.nearest_point  # 更新最近点
            dist = temp2.nearest_dist  # 更新最近距离
        return result(nearest, dist, nodes_visited)
    return travel(tree.root, point, float("inf"))  # 从根节点开始递归
```
:::
::::


## 朴素贝叶斯法

::: right
输出后验概率$P(Y=c_k\vert X=x)$最大的类作为$\dot x$的输出, 所以关键就是学习后验概率
:::

:::: tabs type: card
::: tab 基本方法
__目标__： 用训练集学习联合分布$P(X,Y)$
- 先验概率分布： $P(Y=c_k)$
- 条件概率分布
    $$P(X=x\vert Y=c_k) = P(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)}\vert Y=c_k$$
- 两者相乘得到联合概率$P(X,Y)$

如果$x^{(j)}$的取值有$S_j$个, 分类标签的取值有$K$个, 那么$P(X=x\vert Y=k)$总共有$K\prod_{j=1}^nS_j$个参数, 因此作出`条件独立性假设`($X^{(j)}$相互之间独立), 即分类特征在类别确定的条件下相互之间独立, 这个假设会牺牲一定的分类准确性

$$\begin{aligned}
    P(X=x\vert Y=c_k) &= P(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)}\vert Y=c_k \\
    &= \prod_{j=1}^n P(X^{(j)}=x^{(j)}\vert Y=c_k)
\end{aligned}$$

由于贝叶斯 $P(Y=c_k | X=x)\cdot P(X=x) = P(X=x|Y=c_k)\cdot P(Y=c_k)$ 和 概率积分?$P(X=x) = \sum_k P(X=x|Y=c_k)\cdot P(Y=c_k)$, 我们有

$$\begin{aligned}
    y &= \arg\max_{c_k}P(Y=c_k | X=x)  \\
      &= \arg\max_{c_k}P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}| Y=c_k) 
\end{aligned}$$
:::
::: tab 参数估计
![朴素贝叶斯](~@assets/ml_01_08.png#center)

假设上面这个训练集, 计算$\dot x = (2,S)$的类别$\dot y$

|  先验概率   |  $P(Y=1)=9/15, \quad P(Y=-1) = 6/15$  |
|  :----  | :----  |
| 条件概率 | $P(X^{(1)} = 1 \vert Y=1) = 2/9, \quad P(X^{(1)} = 2 \vert Y=1) = 3/9$ <br>$P(X^{(1)} = 3 \vert Y=1) = 4/9$ |
|         | $P(X^{(1)} = 1 \vert Y=-1) = 3/6, \quad P(X^{(1)} = 2 \vert Y=-1) = 2/6$ <br>$P(X^{(1)} = 3 \vert Y=-1) = 1/6$ |
|         | $P(X^{(2)} = S \vert Y=1) = 1/9, \quad P(X^{(2)} = M \vert Y=1) = 4/9$ <br>$P(X^{(2)} = L \vert Y=1) = 4/9$ |
|         | $P(X^{(2)} = S \vert Y=-1) = 3/6, \quad P(X^{(2)} = M \vert Y=-1) = 2/6$ <br>$P(X^{(2)} = L \vert Y=-1) = 1/6$ |
| 计算$P(Y\vert \dot x)$ | $P(Y=1\vert X^{(1)} =2, X^{(2)} = S) = (9/15)(3/9)(1/9) = 1/45$ |
|                        | $P(Y=-1\vert X^{(1)} =2, X^{(2)} = S) = (6/15)(2/6)(3/6) = 1/15$ |

可以看到$Y=-1$的概率更大, 所以朴素贝叶斯会把他分到`-1`那一类
:::
::: tab 概率为0
![朴素贝叶斯](~@assets/ml_01_08.png#center)

用极大似然估计可能会出现所要估计的概率值为0的情况, 于是加一个$\lambda \geq 0$来平滑, 如果$\lambda=1$, 被称为`Laplacian Smoothing`, 现在假设$\lambda=1$, 重新估计$P(Y|\dot x = (2,S))$

|  先验概率   |  $P(Y=1)=(9+1)/(15+2), \quad P(Y=-1) = (6+1)/(15+2)$  |
|  :----  | :----  |
| 条件概率 | $P(X^{(1)} = 1 \vert Y=1) = (2+1)/(9+3)$ <br>$P(X^{(1)} = 2 \vert Y=1) = (3+1)/(9+3)$ <br>$P(X^{(1)} = 3 \vert Y=1) = (4+1)/(9+3)$ |
|         | $P(X^{(1)} = 1 \vert Y=-1) = (3+1)/(6+3)$ <br>$P(X^{(1)} = 2 \vert Y=-1) = (2+1)/(6+3)$ <br>$P(X^{(1)} = 3 \vert Y=-1) = (1+1)/(6+3)$ |
|         | $P(X^{(2)} = S \vert Y=1) = (1+1)/(9+3)$ <br>$P(X^{(2)} = M \vert Y=1) = (4+1)/(9+3)$ <br>$P(X^{(2)} = L \vert Y=1) = (4+1)/(9+3)$ |
|         | $P(X^{(2)} = S \vert Y=-1) = (3+1)/(6+3)$ <br>$P(X^{(2)} = M \vert Y=-1) = (2+1)/(6+3)$ <br>$P(X^{(2)} = L \vert Y=-1) = (1+1)/(6+3)$ |
| 计算$P(Y\vert \dot x)$ | $P(Y=1\vert X^{(1)} =2, X^{(2)} = S) = (10/17)(4/12)(2/12) = 5/153$ |
|                        | $P(Y=-1\vert X^{(1)} =2, X^{(2)} = S) = (7/17)(3/9)(4/9) = 28/459$ |

还是$Y=-1$的概率更大, 所以贝叶斯+拉普拉斯平滑还是会把他分到`-1`那一类
:::
::: tab 代码
```python
class GausNB():
    def __init__(self):
        self.model = None
    @staticmethod
    def mean(X):  # 均值
        return sum(X) / float(len(X))
    def std(self, X):  # 标准差
        avg = self.mean(X)
        return np.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))
    def gaus_prob(self, x, mean, std):  # 高斯概率密度
        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(std, 2))))
        return (1 / (math.sqrt(2 * math.pi) * std)) * exponent
    def summarize(self, train_data):
        summaries = [(self.mean(i), self.std(i)) for i in zip(*train_data)]
        return summaries  # 返回 [(各特征的均值，标准差),(),()...]]
    def fit(self, X, y):
        labels = list(set(y))
        data = {label: [] for label in labels}
        for x, label in zip(X, y):
            data[label].append(x)
        self.model = {
            label: [len(data[label]) / float(len(X)), self.summarize(value)]
            for label, value in data.items()
        }  # model写入字典 label : [[label概率],[(各特征的均值，标准差),(),()...]]
        return 'GuassNB train Done !'
    def cal_prob(self, input_data):
        prob = {}
        for label, value in self.model.items():
            prob[label] = value[0]  # P(Y=Ck), 此处修正了原作者的初始概率均等问题
            for i in range(len(value[1])):
                mean, std = value[1][i]
                prob[label] *= self.gaus_prob(input_data[i], mean, std)
        return prob
    def predict(self, X_test):
        # {label : prob},按照概率排序，取最后（最大）的【0】标签
        label = sorted(self.cal_prob(X_test).items(), key=lambda x: x[-1])[-1][0]
        return label
    def predict_prob(self, X_test):
        prob = sorted(self.cal_prob(X_test).items(), key=lambda x: x[-1])[-1][1]
        s = sum(i for i in self.cal_prob(X_test).values())
        return prob / s  # 预测概率
    def score(self, X_test, y_test):
        right = 0
        for X, y in zip(X_test, y_test):
            label = self.predict(X)
            if label == y:
                right += 1
        return right / float(len(X_test))
```
:::
::::
